{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHgUjvEvdHyJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk import conlltags2tree, tree2conlltags\n",
    "from nltk.tokenize import StanfordSegmenter\n",
    "from nltk.tag import StanfordNERTagger, StanfordPOSTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=StanfordNERTagger('english.all.3class.distsim.crf.ser.gz','stanford-ner.jar',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 810,
     "status": "error",
     "timestamp": 1557037592052,
     "user": {
      "displayName": "Zhengyu Chen",
      "photoUrl": "https://lh6.googleusercontent.com/-fqulyiKkADI/AAAAAAAAAAI/AAAAAAAAAAc/zoRCYKQJduU/s64/photo.jpg",
      "userId": "14806602938355558554"
     },
     "user_tz": -600
    },
    "id": "L1izCgTAgmOq",
    "outputId": "9df04aae-e460-4f33-91c4-3eec2d88374a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = \"Material/train.json\"\n",
    "train_json = None\n",
    "with open(train) as t:\n",
    "    train_json = json.load(t)\n",
    "# print(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YX6TPLA_qvBz",
    "outputId": "7f96feaa-43ed-48b0-95a1-cda149117144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Kendrick', 'NNP'), ('Lamar', 'NNP'), ('signed', 'VBD'), ('his', 'PRP$'), ('first', 'JJ'), ('contract', 'NN'), ('with', 'IN'), ('Top', 'NNP'), ('Dawg', 'NNP'), ('Entertainment', 'NNP'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "claim = train_json[\"39179\"][\"claim\"]\n",
    "print(nltk.pos_tag(nltk.word_tokenize(claim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Kendrick', 'PERSON'), ('Lamar', 'PERSON'), ('signed', 'O'), ('his', 'O'), ('first', 'O'), ('contract', 'O'), ('with', 'O'), ('Top', 'O'), ('Dawg', 'O'), ('Entertainment', 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "claim = train_json[\"39179\"][\"claim\"]\n",
    "print(st.tag(nltk.word_tokenize(claim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Kendrick/NNP)\n",
      "  (PERSON Lamar/NNP)\n",
      "  signed/VBD\n",
      "  his/PRP$\n",
      "  first/JJ\n",
      "  contract/NN\n",
      "  with/IN\n",
      "  (PERSON Top/NNP Dawg/NNP Entertainment/NNP)\n",
      "  ./.)\n",
      "[('Kendrick', 'NNP', 'B-PERSON'), ('Lamar', 'NNP', 'B-PERSON'), ('signed', 'VBD', 'O'), ('his', 'PRP$', 'O'), ('first', 'JJ', 'O'), ('contract', 'NN', 'O'), ('with', 'IN', 'O'), ('Top', 'NNP', 'B-PERSON'), ('Dawg', 'NNP', 'I-PERSON'), ('Entertainment', 'NNP', 'I-PERSON'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "tree = ne_chunk(pos_tag(word_tokenize(train_json[\"39179\"][\"claim\"])))\n",
    "print(tree)\n",
    "iob_tags = tree2conlltags(tree)\n",
    "print(iob_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\n  NLTK was unable to find stanford-postagger.jar! Set the CLASSPATH\n  environment variable.\n\n  For more information, on stanford-postagger.jar, see:\n    <https://nlp.stanford.edu/software>\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-923cdb293e7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meng_tagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordPOSTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english.all.3class.distsim.crf.ser.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'What is the airspeed of an unladen swallow ?'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/tag/stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStanfordPOSTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/tag/stanford.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_filename, path_to_jar, encoding, verbose, java_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[1;32m     73\u001b[0m         self._stanford_jar = find_jar(\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_JAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_stanford_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         )\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/internals.py\u001b[0m in \u001b[0;36mfind_jar\u001b[0;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[1;32m    852\u001b[0m     return next(\n\u001b[1;32m    853\u001b[0m         find_jar_iter(\n\u001b[0;32m--> 854\u001b[0;31m             \u001b[0mname_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_jar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearchpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_regex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m         )\n\u001b[1;32m    856\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/internals.py\u001b[0m in \u001b[0;36mfind_jar_iter\u001b[0;34m(name_pattern, path_to_jar, env_vars, searchpath, url, verbose, is_regex)\u001b[0m\n\u001b[1;32m    838\u001b[0m             )\n\u001b[1;32m    839\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'='\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n\n===========================================================================\n  NLTK was unable to find stanford-postagger.jar! Set the CLASSPATH\n  environment variable.\n\n  For more information, on stanford-postagger.jar, see:\n    <https://nlp.stanford.edu/software>\n==========================================================================="
     ]
    }
   ],
   "source": [
    "eng_tagger = StanfordPOSTagger('english-bidirectional-distsim.tagger')\n",
    "print(eng_tagger.tag('What is the airspeed of an unladen swallow ?'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zG2JrhbBdHyM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# BOOM\n",
    "# folder = \"Material/wiki-pages-text\"\n",
    "folder = \".\"\n",
    "files = os.listdir(folder)\n",
    "dictionary = {}\n",
    "for file in files:\n",
    "    if not os.path.isdir(file) and file[:4] == 'wiki':\n",
    "#     if not os.path.isdir(file):\n",
    "        with open(folder + '/' + file) as f:\n",
    "            for line in f:\n",
    "                line = line.split(' ')\n",
    "                if len(line) > 2:\n",
    "                    dictionary[(line[0], line[1])] = line[2:]\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jCJ3oNidHyO"
   },
   "outputs": [],
   "source": [
    "with open(\"Material/test-unlabelled.json\") as test_unlabelled:\n",
    "    test = json.load(test_unlabelled)\n",
    "for key, val in test.items():\n",
    "    val['label'] = \"NOT ENOUGH INFO\"\n",
    "    val['evidence'] = []\n",
    "with open(\"result.json\", 'w') as res_file:\n",
    "    json.dump(test, res_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Fact-Verification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
